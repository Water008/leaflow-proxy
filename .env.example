# .env - Local development environment variables
# Copy this file to .env and fill in your values.
# This file should be added to .gitignore.

# The authorization token for the internal LLM service.
# This is required for the proxy to communicate with the LLM backend.
INNER_TOKEN=your_secret_inner_token_here

# An optional authorization key to protect this proxy service itself.
# If set, clients must send a "Authorization: Bearer <key>" header to use the proxy.
# Example: AUTHORIZATION_KEY=your_secret_proxy_key_here
# To disable proxy authorization, leave this commented out or set to empty.
AUTHORIZATION_KEY=your_secret_proxy_key_here

# The port the proxy server will run on.
# Default: 3000
PORT=3000

# The timezone for the server.
# Default: Asia/Shanghai
TZ=Asia/Shanghai

# The base URL for the internal LLM service.
# Default: http://llm.ai-infra.svc.cluster.local
LLM_BASE_URL=http://llm.ai-infra.svc.cluster.local

# HTTP request timeout for calls to the internal LLM service (in milliseconds).
# Default: 8000 (8 seconds)
LLM_REQUEST_TIMEOUT_MS=8000